# Proyecto: An√°lisis de Readmisi√≥n Hospitalaria en Pacientes Diab√©ticos

**Dataset:** Diabetes 130-US Hospitals (1999-2008)  
**Objetivo:** Predecir readmisi√≥n hospitalaria en <30 d√≠as (Clasificaci√≥n)  

---

## ‚ö†Ô∏è IMPORTANTE: Alcance del Proyecto

### ‚úÖ LO QUE HAREMOS:
- An√°lisis exploratorio completo (NumPy, Pandas, Seaborn)
- **Regresi√≥n Log√≠stica** (clasificaci√≥n binaria)
- **√Årboles de Decisi√≥n** para clasificaci√≥n
- **Random Forest y Gradient Boosting**
- **KNN, Naive Bayes o SVM**
- **Redes Neuronales (MLPClassifier)**
- Validaci√≥n Cruzada, GridSearchCV
- M√©tricas de clasificaci√≥n (matriz de confusi√≥n, precision, recall, F1, ROC-AUC)

---

## üë§ PERSONA 1: An√°lisis Exploratorio y Preparaci√≥n de Datos (Albert)

### **Tiempo de exposici√≥n:** 5-7 minutos

### **Tarea 1.1: Carga e Inspecci√≥n Inicial**
**Qu√© hacer:**
- Cargar el dataset usando Pandas desde UCI ML Repository o CSV
- Usar `.info()`, `.describe()`, `.head()`, `.shape` para inspeccionar
- Identificar tipos de datos, cantidad de features (50+), instancias (101,766)
- Detectar valores faltantes con `.isnull().sum()`
- Revisar duplicados en `encounter_id` y `patient_nbr`
- **Demostrar operaciones vectorizadas con NumPy:**
  - Convertir alguna columna num√©rica a array
  - Realizar operaciones (suma, media, normalizaci√≥n) con vectorizaci√≥n
  - Comparar velocidad vs loops tradicionales

**Entregable:**
- Resumen de la estructura del dataset
- Tabla con estad√≠sticas descriptivas clave
- Identificaci√≥n de problemas (missing values, desbalance de clases)

---

### **Tarea 1.2: Limpieza y Transformaci√≥n de Datos**
**Qu√© hacer:**
- **Manejo de valores faltantes:**
  - Decidir estrategia por columna (eliminar, imputar con moda/media, crear categor√≠a "unknown")
  - Documentar decisiones tomadas
- **Variable objetivo:**
  - Convertir `readmitted` a binaria: `<30` ‚Üí 1 (readmitido), resto ‚Üí 0
  - Analizar desbalance de clases
- **Encoding de categ√≥ricas:**
  - One-Hot Encoding para variables nominales (race, gender, admission_type)
  - Label Encoding para ordinales si las hay
- **Feature Engineering (opcional pero recomendado):**
  - Crear `total_visits = num_outpatient + num_inpatient + num_emergency`
  - Crear `medication_changes = change + diabetesMed`
  - Agrupar edades en rangos m√°s amplios si tiene sentido
- **Normalizaci√≥n:**
  - Estandarizar variables num√©ricas con StandardScaler (importante para algunos modelos)

**Entregable:**
- Dataset limpio guardado como `diabetes_clean.csv`
- Documento explicando transformaciones realizadas
- Nuevo shape del dataset despu√©s de encoding

---

### **Tarea 1.3: An√°lisis Exploratorio con Pandas y Visualizaciones**
**Qu√© hacer:**
- **Agregaciones con `.groupby()`:**
  - Tasa de readmisi√≥n por grupo de edad
  - Tasa de readmisi√≥n por raza y g√©nero
  - Promedio de tiempo hospitalizado seg√∫n readmisi√≥n
  - Relaci√≥n entre n√∫mero de medicamentos y readmisi√≥n
  - ¬øInfluye el resultado de HbA1c en la readmisi√≥n?

- **Visualizaciones clave (m√°ximo 3-4):**
  1. **Distribuci√≥n de la variable objetivo** (countplot): ¬øCu√°ntos readmitidos vs no?
  2. **Heatmap de correlaci√≥n** entre variables num√©ricas principales
  3. **Boxplot o violinplot**: Tiempo hospitalizado vs readmisi√≥n
  4. **Barplot**: Tasa de readmisi√≥n por grupo de edad o raza

**Entregable:**
- Notebook con an√°lisis exploratorio completo
- 3-4 gr√°ficas guardadas en alta calidad (PNG/PDF)
- Lista de insights clave para presentar (ej: "Pacientes >70 a√±os tienen 15% m√°s readmisi√≥n")

---

**Puntos clave para tu parte de la exposici√≥n:**
1. Contexto del problema (2 min)
2. Estructura y limpieza del dataset (2 min)
3. Insights principales del EDA (2-3 min)

---

## üë§ PERSONA 2: Modelos Cl√°sicos de Clasificaci√≥n y Optimizaci√≥n (Robert)

### **Tiempo de exposici√≥n:** 5-7 minutos

### **Tarea 2.1: Regresi√≥n Log√≠stica (Baseline)**
**Qu√© hacer:**
- **Preparaci√≥n:**
  - Dividir datos en train/test (80/20 o 70/30)
  - Usar `train_test_split` con `stratify=y` para mantener proporci√≥n de clases
- **Entrenamiento:**
  - Implementar `LogisticRegression` de scikit-learn
  - Entrenar modelo b√°sico con par√°metros por defecto
- **Evaluaci√≥n:**
  - Matriz de confusi√≥n con `confusion_matrix` y visualizarla con Seaborn
  - Calcular accuracy, precision, recall, F1-score
  - Generar classification report completo
- **Interpretaci√≥n:**
  - Analizar coeficientes del modelo (`model.coef_`)
  - Identificar las 10 features m√°s importantes (positivas y negativas)
- **Experimentaci√≥n con umbral:**
  - Probar diferentes thresholds (0.3, 0.5, 0.7)
  - Graficar c√≥mo cambia precision vs recall
  - Curva ROC y calcular AUC

**Entregable:**
- Modelo de regresi√≥n log√≠stica entrenado
- Matriz de confusi√≥n visualizada
- Tabla con m√©tricas baseline
- Gr√°fica de importancia de features
- An√°lisis de impacto del umbral de decisi√≥n

---

### **Tarea 2.2: √Årboles de Decisi√≥n**
**Qu√© hacer:**
- **Modelo b√°sico:**
  - Entrenar `DecisionTreeClassifier` sin restricciones
  - Evaluar con las mismas m√©tricas que regresi√≥n log√≠stica
- **Visualizaci√≥n del √°rbol:**
  - Usar `plot_tree` de sklearn o `export_graphviz`
  - Mostrar primeras 3-4 capas del √°rbol (el completo ser√° gigante)
  - Interpretar las primeras divisiones: ¬øqu√© features usa?
- **Diagn√≥stico de overfitting:**
  - Calcular accuracy en train y test
  - Si train >> test ‚Üí overfitting detectado
  - Crear curvas de aprendizaje (learning curves)
- **Experimentaci√≥n con hiperpar√°metros:**
  - Probar diferentes `max_depth` (3, 5, 10, 20, None)
  - Probar `min_samples_leaf` (1, 5, 10, 50)
  - Graficar accuracy train vs test seg√∫n profundidad
  - Identificar el punto √≥ptimo

**Entregable:**
- √Årbol de decisi√≥n visualizado (primeras capas)
- Comparativa de hiperpar√°metros (tabla o gr√°fica)
- Curvas de aprendizaje mostrando overfitting
- Modelo de √°rbol optimizado

---

### **Tarea 2.3: Validaci√≥n Cruzada y Comparativa**
**Qu√© hacer:**
- **Validaci√≥n Cruzada:**
  - Aplicar `cross_val_score` con k=5 o k=10 folds
  - Calcular media y desviaci√≥n est√°ndar de las m√©tricas
  - Comparar resultados con simple train/test
- **GridSearchCV para optimizaci√≥n:**
  - Definir grid de hiperpar√°metros para el mejor modelo hasta ahora
  - Para √°rbol: `{'max_depth': [5, 10, 15], 'min_samples_leaf': [5, 10, 20]}`
  - Ejecutar b√∫squeda con scoring='f1' (importante en datos desbalanceados)
  - Obtener mejores par√°metros
- **Tabla comparativa:**
  - Comparar Regresi√≥n Log√≠stica vs √Årbol b√°sico vs √Årbol optimizado
  - M√©tricas: Accuracy, Precision, Recall, F1, AUC, tiempo de entrenamiento
  - A√±adir columna de interpretabilidad (subjetiva)

**Entregable:**
- Resultados de validaci√≥n cruzada
- Mejores hiperpar√°metros encontrados
- Tabla comparativa completa de modelos
- Recomendaci√≥n preliminar

---

**Puntos clave para tu parte de la exposici√≥n:**
1. Baseline con regresi√≥n log√≠stica y an√°lisis de coeficientes (2 min)
2. √Årboles de decisi√≥n, overfitting y optimizaci√≥n (2-3 min)
3. Comparativa de modelos cl√°sicos (2 min)

---

## üë§ PERSONA 3: Modelos Avanzados (Ensembles y Comparativa Final) (Linda)

### **Tiempo de exposici√≥n:** 6-8 minutos

### **Tarea 3.1: Random Forest y Gradient Boosting**
**Qu√© hacer:**
- **Random Forest:**
  - Entrenar `RandomForestClassifier` con par√°metros base
  - Empezar con n_estimators=100
  - Evaluar con mismas m√©tricas
  - Analizar importancia de features con `feature_importances_`
  - Comparar importancias con las de regresi√≥n log√≠stica
- **Gradient Boosting:**
  - Entrenar `GradientBoostingClassifier`
  - Empezar con n_estimators=100, learning_rate=0.1
  - Evaluar y comparar
- **Explicaci√≥n de filosof√≠as:**
  - Preparar explicaci√≥n visual de Bagging (Random Forest):
    - M√∫ltiples √°rboles independientes en paralelo
    - Cada uno con subconjunto aleatorio de datos y features
    - Votaci√≥n por mayor√≠a
  - Preparar explicaci√≥n de Boosting (Gradient Boosting):
    - √Årboles secuenciales que corrigen errores previos
    - Cada √°rbol aprende de los residuos del anterior
- **Optimizaci√≥n:**
  - GridSearchCV para el mejor de los dos
  - Para RF: `{'n_estimators': [100, 200], 'max_depth': [10, 20, None]}`
  - Para GB: `{'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}`
- **Comparativa:**
  - Tiempo de entrenamiento
  - Rendimiento
  - Interpretabilidad (importancia de features)

**Entregable:**
- Modelos Random Forest y Gradient Boosting entrenados
- Gr√°fica de importancia de features
- Diagrama explicativo de Bagging vs Boosting
- Modelo ensemble optimizado

---

### **Tarea 3.2: Modelos Alternativos (KNN, Naive Bayes, SVM)**
**Qu√© hacer:**
- **Seleccionar 2 de estos 3 modelos:**
  
  **Opci√≥n A - K-Nearest Neighbors:**
  - Entrenar `KNeighborsClassifier`
  - Probar diferentes valores de k (3, 5, 10, 20)
  - Justificaci√≥n: Simple, no param√©trico, bueno para datos locales
  - Desventaja: Lento con datasets grandes (101k instancias)
  
  **Opci√≥n B - Naive Bayes:**
  - Entrenar `GaussianNB` (para features continuas)
  - Justificaci√≥n: R√°pido, funciona bien con muchas features, asume independencia
  - Evaluar si la asunci√≥n de independencia se cumple
  
  **Opci√≥n C - Support Vector Machine:**
  - Entrenar `SVC` con kernel='rbf'
  - Justificaci√≥n: Potente para clasificaci√≥n binaria
  - Desventaja: Muy lento con datasets grandes (considerar SVC con kernel lineal)

- **An√°lisis cr√≠tico:**
  - ¬øCu√°l es modelo m√°s adecuado para este problema espec√≠fico?
  - Considerar: tama√±o del dataset, tipo de features, interpretabilidad
  - Comparar tiempos de entrenamiento

**Entregable:**
- 2 modelos alternativos entrenados y evaluados
- Justificaci√≥n de por qu√© elegiste esos 2
- Comparaci√≥n de rendimiento y tiempo

---

### **Tarea 3.3: Red Neuronal MLP (opcional pero recomendado)**
**Qu√© hacer:**
- **Entrenamiento b√°sico:**
  - Implementar `MLPClassifier` de scikit-learn
  - Arquitectura simple: hidden_layers=(100, 50) o similar
  - Usar activation='relu', solver='adam'
  - Establecer max_iter=500 y early_stopping=True
- **Comparativa con modelos tradicionales:**
  - Evaluar con mismas m√©tricas
  - ¬øRealmente supera a Random Forest/Gradient Boosting?
  - Considerar tiempo de entrenamiento
- **Reflexi√≥n cr√≠tica:**
  - "Romper el mito" de que la red neuronal siempre gana
  - Para datos tabulares, los ensembles suelen ser mejores
  - Discutir cu√°ndo S√ç tendr√≠a sentido usar redes neuronales

**Entregable:**
- Modelo MLP entrenado
- Comparativa honesta con otros modelos
- Reflexi√≥n sobre cu√°ndo usar cada tipo de modelo

---

### **Tarea 3.4: Comparativa Final y Selecci√≥n del Modelo**
**Qu√© hacer:**
- **Tabla comparativa completa:**
  - Incluir TODOS los modelos probados:
    1. Regresi√≥n Log√≠stica
    2. √Årbol de Decisi√≥n (optimizado)
    3. Random Forest
    4. Gradient Boosting
    5. 2 modelos alternativos
    6. MLP
  - Columnas: Accuracy, Precision, Recall, F1, ROC-AUC, Tiempo entrenamiento, Interpretabilidad
  
- **An√°lisis de trade-offs:**
  - Interpretabilidad vs Rendimiento
  - Velocidad vs Precisi√≥n
  - Simplicidad vs Complejidad
  
- **Selecci√≥n del modelo final:**
  - Considerar objetivo de negocio: ¬øQu√© es peor?
    - Falso Negativo: No detectar una readmisi√≥n real (paciente vuelve al hospital)
    - Falso Positivo: Predecir readmisi√≥n innecesaria (recursos mal asignados)
  - Si FN es peor ‚Üí priorizar **Recall**
  - Si balance ‚Üí priorizar **F1-score**
  - Justificar elecci√≥n del modelo ganador
  
- **Recomendaciones finales:**
  - Modelo recomendado para producci√≥n
  - Features m√°s importantes a monitorear
  - Posibles mejoras futuras

**Entregable:**
- Tabla comparativa profesional (visual)
- An√°lisis de trade-offs con ejemplos reales
- Modelo final seleccionado y justificado
- Recomendaciones para implementaci√≥n

---

**Puntos clave para tu parte de la exposici√≥n:**
1. Random Forest vs Gradient Boosting: filosof√≠as y resultados (2-3 min)
2. Modelos alternativos y MLP: ¬øcu√°ndo usar cada uno? (2 min)
3. Comparativa final y selecci√≥n del modelo ganador con justificaci√≥n de negocio (2-3 min)

---

## üìä RESUMEN DE VISUALIZACIONES (m√°ximo 9 en total)

### Persona 1 (3-4 gr√°ficas):
1. Distribuci√≥n de variable objetivo (desbalance de clases)
2. Heatmap de correlaci√≥n
3. Tiempo hospitalizado vs readmisi√≥n
4. Tasa de readmisi√≥n por edad/raza

### Persona 2 (2-3 gr√°ficas):
1. Matriz de confusi√≥n (regresi√≥n log√≠stica)
2. Importancia de features (regresi√≥n log√≠stica o √°rbol)
3. Curvas de aprendizaje (overfitting en √°rbol)

### Persona 3 (2-3 gr√°ficas):
1. Comparaci√≥n Bagging vs Boosting (diagrama conceptual)
2. Importancia de features (Random Forest)
3. Tabla/gr√°fica comparativa final de todos los modelos

---

## üéØ ESTRUCTURA SUGERIDA DE LA PRESENTACI√ìN (20 min)

1. **Introducci√≥n** (2 min) - Persona 1
   - Contexto del problema
   - Importancia cl√≠nica y econ√≥mica
   - Objetivo del proyecto

2. **Exploraci√≥n y preparaci√≥n** (5 min) - Persona 1
   - Estructura del dataset
   - Limpieza y transformaciones
   - Insights principales del EDA

3. **Modelos cl√°sicos** (5 min) - Persona 2
   - Regresi√≥n log√≠stica (baseline)
   - √Årboles de decisi√≥n y overfitting
   - Validaci√≥n cruzada y optimizaci√≥n

4. **Modelos avanzados** (6 min) - Persona 3
   - Random Forest y Gradient Boosting
   - Modelos alternativos
   - Comparativa completa

5. **Conclusiones y recomendaciones** (2 min) - Persona 3
   - Modelo final seleccionado
   - Justificaci√≥n de negocio
   - Pr√≥ximos pasos

---

## ‚úÖ CHECKLIST FINAL

### Antes de la presentaci√≥n:
- [ ] Notebook limpio y bien comentado
- [ ] Todas las gr√°ficas guardadas en alta calidad
- [ ] Tabla comparativa final completa
- [ ] Modelo final guardado (pickle o joblib)
- [ ] Presentaci√≥n de diapositivas preparada
- [ ] Ensayo de timing (20 min totales)

### Durante la presentaci√≥n:
- [ ] Explicar decisiones tomadas, no solo resultados
- [ ] Justificar por qu√© NO usamos regresi√≥n lineal
- [ ] Enfatizar la importancia del contexto m√©dico
- [ ] Mostrar trade-offs, no solo "el mejor modelo"
- [ ] Ser honestos con limitaciones